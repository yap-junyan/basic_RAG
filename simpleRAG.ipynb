{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "# ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from sentence_transformers import CrossEncoder\n",
    "from textwrap import dedent\n",
    "from dotenv import load_dotenv\n",
    "from hashlib import sha256\n",
    "from typing import List\n",
    "from IPython.display import display, Markdown\n",
    "import chromadb\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining some functions to organise the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load documents\n",
    "def load_documents(file_directory: str) -> List[Document]:\n",
    "    loader = PyPDFDirectoryLoader(file_directory)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "\n",
    "# Function to split documents into chunks and shift the raw files to the saved directory\n",
    "def prepare_documents(documents: List[Document], chunk_size: int = 500, chunk_overlap: int = 200) -> List[Document]:\n",
    "    # Breaking down documents into chunks\n",
    "    splitter = CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    docs = splitter.split_documents(documents)\n",
    "    \n",
    "    # Shifting the files in the 'raw' directory to the 'saved' directory\n",
    "    if not os.path.exists(\"../guides/saved\"):\n",
    "        os.makedirs(\"../guides/saved\")\n",
    "        \n",
    "    for file in os.listdir(\"../guides/raw\"):\n",
    "        shutil.move(os.path.join(os.path.abspath(\"../guides/raw\"), file), os.path.join(os.path.abspath(\"../guides/saved\"), file))\n",
    "    \n",
    "    return docs\n",
    "\n",
    "\n",
    "# Function to add documents to a collection in the vector database, and returns the vector database\n",
    "def add_to_vector_db(docs: List[Document], collection_name: str, \n",
    "                     embeddings: HuggingFaceInferenceAPIEmbeddings) -> Chroma:\n",
    "    # Initialise ChromaDB client\n",
    "    if not os.path.exists(\"./chroma_db_index\"):\n",
    "        os.mkdir(\"./chroma_db_index\")\n",
    "    chroma_client = chromadb.PersistentClient(path=\"./chroma_db_index\")\n",
    "    \n",
    "    # Get/Create a collection\n",
    "    collection = chroma_client.get_or_create_collection(\n",
    "        name=collection_name,\n",
    "    )\n",
    "    \n",
    "    # Creating ids for docs\n",
    "    ids = [sha256(doc.page_content.encode('utf-8')).hexdigest() for doc in docs]\n",
    "\n",
    "    embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
    "        model=\"sentence-transformers/all-MiniLM-l6-v2\",\n",
    "        api_key=os.getenv(\"HF_TOKEN\")\n",
    "        )\n",
    "\n",
    "    # Adding documents to the collection\n",
    "    db = Chroma.from_documents(\n",
    "        client=chroma_client,\n",
    "        collection_name=\"pbs-user-guide\",\n",
    "        documents=docs,\n",
    "        embedding=embeddings,\n",
    "        ids = ids\n",
    "    )\n",
    "    \n",
    "    return db\n",
    "\n",
    "\n",
    "# Function to initialise the existing vector database should there be no new documents to be added\n",
    "def get_vector_db(collection_name: str, embeddings: HuggingFaceInferenceAPIEmbeddings) -> Chroma:\n",
    "    if not os.path.exists(\"./chroma_db_index\"):\n",
    "        raise FileNotFoundError(\"No vector database found. Please add documents to the vector database.\")\n",
    "    \n",
    "    chroma_client = chromadb.PersistentClient(path=\"./chroma_db_index\")\n",
    "    \n",
    "    db = Chroma(client=chroma_client, collection_name=collection_name, \n",
    "                embedding_function=embeddings,\n",
    "                )\n",
    "    \n",
    "    return db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading our documents and storing them in a vector database (ChromaDB) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading our documents from the directory \n",
    "documents = load_documents(\"../guides/raw/\")\n",
    "# Embeddings for indexing\n",
    "embeddings = HuggingFaceInferenceAPIEmbeddings(model=\"sentence-transformers/all-MiniLM-l6-v2\", \n",
    "                                               api_key=os.getenv(\"HF_TOKEN\"))\n",
    "\n",
    "if documents:\n",
    "    docs = prepare_documents(documents)\n",
    "    print(f\"Number of documents: {len(docs)}\")\n",
    "    print(\"Example of a document: \\n\", docs[0].page_content)\n",
    "    db = add_to_vector_db(docs, \"pbs-user-guide\", embeddings=embeddings)\n",
    "\n",
    "# if there are no documents, initialise the existing vector database    \n",
    "else: \n",
    "    db = get_vector_db(\"pbs-user-guide\", embeddings=embeddings)\n",
    "    \n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='PBS Professional \\n  \\n2021.1.2 \\n  \\nUser’s \\n Guide \\nUG-v \\nContents \\nAbout PBS Documentation \\n ix\\n1 \\nGetting Started with PBS \\n1 \\n1.1 \\nWhy Use PBS? \\n . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  \\n1 \\n1.2 \\nPBS Tasks and Components \\n . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  \\n1 \\n1.3 \\nInterfaces to PBS \\n . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  \\n3 \\n1.4 \\nSetting Up Your Environment \\n . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  \\n4 \\n2 \\nSubmitting a PBS Job \\n11 \\n2.1 \\nIntroduction to the PBS Job \\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  \\n11 \\n2.2 \\nThe PBS Job Script \\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  \\n14 \\n2.3 \\nSubmitting a PBS Job \\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  \\n19 \\n2.4 \\nJob Submission Recommendations and Advice \\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  \\n23 \\n2.5 \\nJob Submission Options \\n . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  \\n24 \\n2.6 \\nJob Submission Caveats \\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  \\n30 \\n3 \\nJob Input & Output Files \\n31 \\n3.1 \\nIntroduction to Job File I/O in PBS \\n . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  \\n31 \\n3.2 \\nInput/Output File Staging \\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  \\n31 \\n3.3 \\nManaging Output and Error Files \\n . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  \\n40 \\n4 \\nAllocating Resources & Placing Jobs \\n49 \\n4.1 \\nWhat is a Vnode? \\n . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  \\n49 \\n4.2 \\nPBS Resources \\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  \\n49 \\n4.3 \\nRequesting Resources \\n . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  \\n51 \\n4.4 \\nHow Resources are Allocated to Jobs \\n . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  \\n59 \\n4.5 \\nLimits on Resource Usage \\n . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  \\n61 \\n4.6 \\nViewing Resources \\n . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  \\n63 \\n4.7 \\nSpecifying Job Placement \\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  \\n64 \\n4.8 \\nBackward Compatibility \\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  \\n70 \\n5 \\nMultiprocessor Jobs \\n77 \\n5.1 \\nSubmitting Multiprocessor Jobs \\n . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  \\n77 \\n5.2 \\nUsing MPI with PBS \\n . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  \\n81 \\n5.3 \\nUsing PVM with PBS \\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  \\n102 \\n5.4 \\nUsing OpenMP with PBS \\n . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  \\n103 \\n5.5 \\nHybrid MPI-OpenMP Jobs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105', metadata={'page': 4, 'source': '..\\\\guides\\\\raw\\\\PBSUserGuide2021.1.2.pdf'}),\n",
       " Document(page_content=\"Submitting a PBS Job Chapter  2\\nPBS Professional  2021.1.2  User’s  Guide UG-13You'll need the job identifier for any actions involving the job, such as checking job status, modifying the job, tracking \\nthe job, or deleting the job.\\nThe largest possible job ID is the 7-digit number 9,999,999. After this has been reached, job IDs start again at zero. \\n2.1.4 Shell Script(s) for Your Job\\nWhen PBS runs your job, PBS starts the top shell that you specify for the job.  The top shell defaults to your login shell \\non the execution host, but you can set another using the job's Shell_Path_List  attribute.  See section 2.3.3.1, “Specifying \\nthe Top Shell for Your Job”, on page 19 .  \\nUnder Linux, if you do not specify a shell inside the job script, PBS defaults to using /bin/sh .  If you specify a differ -\\nent shell inside the job script, the top shell spawns that shell to run the script; see section 2.3.3.2, “Specifying Job Script \\nShell or Interpreter”, on page 20 .  \\nUnder Windows, the job shell is the same as the top shell.  \\n2.1.5 Scratch Space for Jobs \\nWhen PBS runs your job, it creates a temporary scratch directory for the job on each execution host.  Your administrator \\ncan specify a root for the temporary directory on each execution host using the $tmpdir  MoM parameter.    \\nPBS removes the directory when the job is finished.  The location of the temporary directory is set by PBS; you should not set \\nTMPDIR . \\nYour job script can access the scratch space.  For example:\\nLinux:\\ncd $TMPDIR\\nWindows:\\ncd %TMPDIR%\\nFor scratch space for MPI jobs, see section 5.2.3, “Caveats for Using MPIs”, on page 84 .\\n2.1.5.1 Temporary Scratch Space Location Under Linux\\nIf your administrator has not specified a temporary directory , the root of the temporary directory is /var/tmp .  PBS sets \\nthe TMPDIR  environment variable to the full path to the temporary scratch directory.\\n2.1.5.2 Temporary Scratch Space Location Under W indows\\nUnder Windows, PBS creates the temporary directory and sets TMP  to the value of the Windows %TMPDIR%  environ -\\nment variable.  If your administrator has not specified a temporary directory, PBS creates the temporary directory under either \\n\\\\winnt\\\\temp  or \\\\windows\\\\temp .\\n2.1.6 Types of Jobs\\nPBS allows you to submit standard batch jobs or interactive  jobs.  The difference is that while the interactive job runs, \\nyou have an interactive session running, giving you interactive access to job processes.  There is no interactive access to a standard batch job.  We cover interactive jobs in \\nsection 6.1 1, “Running Your Job Interactively”, on page 121 .\", metadata={'page': 24, 'source': '..\\\\guides\\\\raw\\\\PBSUserGuide2021.1.2.pdf'}),\n",
       " Document(page_content=\"Chapter  1 Getting Started with PBS\\nUG-2 PBS  Professional 2021.1.2  User’s  Guide1.2.2 PBS Components\\nPBS consists of a set of commands and system daemons/services, shown here:      \\nFigure 1-1: Jobs are submitted to the PBS server .  The scheduler chooses where and when to run the \\njobs, and the server sends the jobs to MoM.  PBS commands communicate with the server .\\nThe server , scheduler, and communication daemons run on the server host.  A machine that executes jobs is called an \\nexecution host.  Each execution host runs a MoM daemon.  The server host can run a MoM daemon.  One server man -\\nages any number of MoM daemons.  Commands can be run from the server host, execution hosts, and command-only cli -\\nent hosts.  The server/scheduler/communication host, the execution hosts, and the client hosts are called a PBS complex.  \\nCommands\\nPBS provides a set of commands that you can use to submit, monitor , alter, and delete jobs.  The PBS com -\\nmands can be installed on any supported platform, with or without the other PBS components.  \\nSome PBS commands can be run by any PBS user, while some require administrator or operator privilege.  Some commands provide extended features for administrators and operators.\\nJob\\nA PBS job is a task, in the form of a shell script, cmd batch file, Python script, etc. describing the commands \\nand/or applications you want to run.  You hand your task off to PBS, where it becomes a PBS job.\\nServer\\nThe PBS server manages jobs for the PBS complex.  PBS commands talk to the PBS server , jobs are submitted \\nto the server, and the server queues the jobs and sends them to execution hosts.\\nScheduler\\nThe scheduler runs jobs according to the policy specified by the site administrator .  The scheduler matches each \\njob's requirements with available resources, and prioritizes jobs and allocates resources according to policy.  \\nMoM\\nMoM manages jobs once they are sent to the execution host.  One MoM manages the jobs on each execution \\nhost.  MoM stages files in, runs any prologue, starts each job, monitors the job, stages files out and returns out -\\nput to the job submitter, runs any epilogue, and cleans up after the job.  MoM can also run any execution host hooks.  \\nMoM creates a new session that is as identical to your login session as is possible.  For example, under Linux, if the job submitter's login shell is \\ncsh, then MoM creates a session in which .login  is run as well as .cshrc .\\nMoM is a reverse-engineered acronym that stands for Machine-oriented Mini-server. Batch\\n Jobs Jobs\\nKernelPBS\\nCommands\\nServer\\nSchedulerMoM\", metadata={'page': 13, 'source': '..\\\\guides\\\\raw\\\\PBSUserGuide2021.1.2.pdf'}),\n",
       " Document(page_content='1\\nPBS Professional  2021.1.2  User’s  Guide UG-1Getting Started with PBS\\n1.1 Why Use PBS?\\nPBS frees you from the mechanics of getting your work done; you don\\'t need to shepherd each job to the right machine, \\nget input and output copied back and forth, or wait until a particular machine is available.  You need only specify require -\\nments for the tasks you want executed, and hand the tasks off to PBS.  PBS holds each task until a slot opens up, then \\ntakes care of copying input files to the execution directory, executing the task, and returning the output to you.\\nPBS keeps track of which hardware is available, and all waiting and running tasks.  PBS matches the requirements of each of your tasks to the right hardware and time slot, and makes sure that tasks are run according to the site\\'s policy.  PBS also maximizes usage and throughput.\\n1.2 PBS T asks and Components\\n1.2.1 PBS T asks\\nPBS is a distributed workload management system.  PBS manages and monitors the computational workload for one or \\nmore computers.  PBS does the following:\\nQueuing jobs\\nPBS collects jobs (work or tasks) to be run on one or more computers. Users submit jobs to PBS, where they are \\nqueued up until PBS is ready to run them.\\nScheduling jobs\\nPBS selects which jobs to run, and when and where to run them, according to the resources requested by the job, \\nand the policy specified by the site administrator.  PBS allows the administrator to prioritize jobs and allocate resources in a wide variety of ways, to maximize efficiency and/or throughput.\\nMonitoring jobs\\nPBS tracks system resources, enforces usage policy , and reports usage.  PBS tracks job completion, ensuring \\nthat jobs run despite system outages.  \\nReturning Output\\nPBS returns job output to the location you specify .  See Chapter 3, \"Job Input & Output Files\", on page 31 .', metadata={'page': 12, 'source': '..\\\\guides\\\\raw\\\\PBSUserGuide2021.1.2.pdf'}),\n",
       " Document(page_content=\"Chapter  2 Submitting a PBS Job\\nUG-12 PBS  Professional 2021.1.2  User’s  Guide2.1.1 Lifecycle of a PBS Job, Briefly\\nYour PBS job has the following lifecycle:\\n1. You write a job script\\n2. You submit the job to PBS3. PBS accepts the job and returns a job ID to you4. The PBS scheduler finds the right place and time to run your job, and sends your job to the selected execution host(s)5. Application licenses are checked out6. On each execution host, if specified, PBS creates a job-specific staging and execution directory7. PBS sets \\nPBS_JOBDIR  and the job's jobdir  attribute to the path of the job's staging and execution directory . \\n8.On each execution host allocated to the job, PBS creates a temporary scratch directory .  \\n9.PBS sets the TMPDIR  environment variable to the pathname of the temporary directory .  \\n10.If any errors occur during directory creation or the setting of variables, the job is requeued. \\n11.Input files or directories are copied to the primary execution host\\n•If it exists, the prologue runs on the primary execution host, with its current working directory set to \\nPBS_HOME/mom_priv , and with PBS_JOBDIR  and TMPDIR  set in its environment. \\n12. The job is run as you on the primary execution host.13. The job's associated tasks are run as you on the execution host(s).14. If it exists, the epilogue runs on the primary execution host, with its current working directory set to the path of the \\njob's staging and execution directory, and with \\nPBS_JOBDIR  and TMPDIR  set in its environment.\\n15.Output files or directories are copied to specified locations\\n16.Temporary files and directories are cleaned up\\n17.Application licenses are returned to pool\\nFor more detail about the lifecycle of a job, see section 3.2.8, “Detailed Description of Job Lifecycle”, on page 37 .\\n2.1.2 Where and How Your PBS Job Runs\\nYour PBS jobs run on hosts that the administrator has designated to PBS as execution hosts.  The PBS scheduler chooses \\none or more execution hosts that have the resources that your job requires. \\nPBS runs your jobs under your user account.  This means that your login and logout files are executed for each job, and some of your environment goes with the job.  It's important to make sure that your login and logout files don't interfere with your jobs; see \\nsection 1.4.2, “Setting Up Your Linux Environment”, on page 5 .\\n2.1.3 The Job Identifier\\nAfter you submit a job, PBS returns a job identifier .  Format for a job:\\n<sequence number>.<server name>\\nFormat for a job array:\\n<sequence number>[].<server name>.<domain>\", metadata={'page': 23, 'source': '..\\\\guides\\\\raw\\\\PBSUserGuide2021.1.2.pdf'}),\n",
       " Document(page_content='2\\nPBS Professional  2021.1.2  User’s  Guide UG-11Submitting a PBS Job\\n2.1 Introduction to the PBS Job\\nTo use PBS, you create a batch job , usually just called a job, which you then hand off, or submit , to PBS. A batch job is a \\nset of commands and/or applications you want to run on one or more execution machines, contained in a file or typed at the command line.  You can include instructions which specify the characteristics such as job name and resource require\\n-\\nments such as memory, CPU time, etc., that your job needs.  The job file can be a shell script under Linux, a cmd batch \\nfile under Windows, a Python script, a Perl script, etc.  \\nFor example, here is a simple PBS batch job file which requests one hour of time, 400MB of memory, 4 CPUs, and runs \\nmy_application : \\n#!/bin/sh\\n#PBS -l walltime=1:00:00\\n#PBS -l mem=400mb,ncpus=4\\n./my_application\\nTo submit the job to PBS, you use the qsub  command, and give the job script as an argument to qsub .  For example, to \\nsubmit the script named \" my_script \":\\nqsub my_script\\nWe will go into the details of job script creation in section 2.2, “The PBS Job Script”, on page 14 , and job submission in \\nsection 2.3, “Submitting a PBS Job”, on page 19 .', metadata={'page': 22, 'source': '..\\\\guides\\\\raw\\\\PBSUserGuide2021.1.2.pdf'}),\n",
       " Document(page_content='Submitting a PBS Job Chapter  2\\nPBS Professional  2021.1.2  User’s  Guide UG-192.3 Submitting a PBS Job\\n2.3.1 Prerequisites for Submitting Jobs\\nBefore you submit any jobs, set your environment appropriately .  Follow the instructions in section 1.4, “Setting Up Your \\nEnvironment”, on page 4 .\\n2.3.2 Ways to Submit a PBS Job\\nYou can use the qsub  command to submit a normal or interactive job to PBS:\\n•You can call qsub  with a job script; see section 2.3.3, “Submitting a Job Using a Script”, on page 19\\n•You can call qsub  with an executable and its arguments; see section 2.3.4, “Submitting Jobs by Specifying Execut -\\nable on Command Line”, on page 22\\n•You can call qsub  and give keyboard input; see section 2.3.5, “Submitting Jobs Using Keyboard Input”, on page 22\\nYou can use an Altair front-end product to submit and monitor jobs; go to www .pbsworks.com .  \\n2.3.3 Submitting a Job Using a Script\\nYou submit a job to PBS using the qsub  command.  For details on qsub , see “qsub” on page 214 of the PBS Profes -\\nsional Reference Guide .   To submit a PBS job, type the following: \\n•Linux shell script:\\nqsub <name of shell script>\\n•Linux Python or Perl script:\\nqsub <name of Python or Perl job script> \\n•Windows command script:\\nqsub <name of job script>\\n•Windows Python script:\\nqsub -S %PBS_EXEC%\\\\bin\\\\pbs_python.exe <name of python job script>\\nIf the path contains any spaces, it must be quoted, for example:\\nqsub -S \"%PBS_EXEC%\\\\bin\\\\pbs_python.exe\" <name of python job script>\\n2.3.3.1 Specifying the T op Shell for Your Job\\nYou can can specify the path and name of the shell to use as the top shell for your job.  The rules for specifying the top \\nshell are different for Linux and Windows; do not skip the following subsections numbered 2.3.3.1.i  and 2.3.3.1.ii .\\nThe Shell_Path_List  job attribute specifies the top shell; the default is your login shell on the execution host.  You can \\nset this attribute using the the following:\\n•The \"-S <path list> \" option to qsub\\n•The #PBS Shell_Path_List=<path list>  PBS directive\\nThe option argument path list  has this form:\\n<path>[@<hostname>][,<path>[@<hostname>],...] \\nYou must supply a path list  if you attempt to set Shell_Path_List , otherwise, you will get an error.  You can specify only \\none path for any host you name.  You can specify only one path that doesn\\'t have a corresponding host name.', metadata={'page': 30, 'source': '..\\\\guides\\\\raw\\\\PBSUserGuide2021.1.2.pdf'}),\n",
       " Document(page_content='Chapter  2 Submitting a PBS Job\\nUG-20 PBS  Professional 2021.1.2  User’s  GuidePBS chooses the path whose host name matches the name of the execution host. If no matching host is found, then PBS \\nchooses the path specified without a host, if one exists. \\n2.3.3.1.i Specifying Job T op Shell Under Linux\\nOn Linux, the job\\'s top shell is the one MoM starts when she starts your job, and the job shell is the shell or interpreter \\nthat runs your job script commands. \\nUnder Linux, you can use any shell such as csh or sh, by specifying qsub -S <path> .   You cannot use Perl or \\nPython as your top shell.  \\nExample 2-1:  Using bash :\\nqsub -S /bin/bash <script name>\\n2.3.3.1.ii Specifying Job T op Shell Under W indows\\nOn Windows, the job shell is the same as the top shell.  \\nUnder Windows, you can specify a shell or an interpreter such as Perl or Python, and if your job script is Perl or Python, you must specify the language using an option to \\nqsub ; you cannot specify it in the job script.\\nExample 2-2:  Running a Python script on Windows: \\nqsub -S \"C:\\\\Program Files\\\\PBS\\\\exec\\\\bin\\\\pbs_python.exe\" <script name>\\n2.3.3.1.iii Caveats for Specifying Job T op Shell\\nIf you specify a relative path for the top shell, the full path must be available in your PATH  environment variable on the \\nexecution host(s).  We recommend specifying the full path.\\n2.3.3.2 Specifying Job Script Shell or Interpreter\\n2.3.3.2.i Specifying Job Script Shell or Interpreter Under Linux\\nIf you don\\'t specify a shell for the job script, it defaults to /bin/sh .  You can use any shell, and you can use an inter -\\npreter such as Perl or Python.\\nYou specify the shell or interpreter in the first line of your job script.  The top shell spawns the specified process, and thi s \\nprocess runs the job script.  For example, to use /bin/sh  to run the script, use the following as the first line in your job \\nscript:\\n#!/bin/sh\\nTo use Perl or Python to run your script, use the path to Perl or Python as the first line in your script:\\n#!/usr/bin/perl\\nor\\n#!/usr/bin/python\\n2.3.3.2.ii Specifying Job Script Shell or Interpreter Under W indows\\nUnder Windows, the job shell or interpreter is the same as the top shell or interpreter.  You can specify the top/job shell or \\ninterpreter, but not a separate job shell or interpreter.  To use a non-default shell or interpreter, you must specify it using  \\nan option to qsub :\\nqsub -S <path to shell or interpr eter> <script name>\\n2.3.3.3 Examples of Submitting Jobs Using Scripts\\nExample 2-3:  Our job script is named \" myjob \".  We can submit it by typing:\\nqsub myjob', metadata={'page': 31, 'source': '..\\\\guides\\\\raw\\\\PBSUserGuide2021.1.2.pdf'}),\n",
       " Document(page_content=\"Getting Started with PBS Chapter  1\\nPBS Professional  2021.1.2  User’s  Guide UG-31.3 Interfaces to PBS\\nPBS provides a command-line interface, and Altair offers a web-based front end to PBS called Access, which is a sepa -\\nrate product.  This document describes the PBS command-line interface.  For information on Access, see \\nwww.altair.com .  \\n1.3.1 PBS Commands\\nPBS provides a set of commands that allow you to submit, monitor , and manage your jobs.  Some PBS commands can be \\nused by any PBS user; some can be used only by administrators, and some have different behavior depending on the role of the person invoking them.  In this document, we describe the commands that can be used by any PBS user.  For a com\\n-\\nplete description of all commands and their requirements, see “List of Commands” on page 22 of the PBS Professional \\nReference Guide .       \\nTable 1-1: PBS Commands\\nCommand Action\\nmpiexec Runs MPI programs under PBS on Linux\\npbsdsh Distributes tasks to vnodes under PBS\\npbsnodes Query PBS host or vnode status, mark hosts free or of fline, change the comment for a \\nhost, or output vnode information\\npbs_attach Attaches a session ID to a PBS job\\npbs_hostn Reports hostname and network address(es)\\npbs_lamboot PBS front end to LAM's lamboot  program\\npbs_login Caches encrypted user password for authentication\\npbs_mpihp Runs an MPI application in a PBS job with HP  MPI\\npbs_mpilam Runs MPI programs under PBS with LAM MPI\\npbs_mpirun Runs MPI programs under PBS with MPICH\\npbs_python Python interpreter for debugging a hook script from the command line\\npbs_ralter Modifies an existing advance, standing, or job-specific reservation\\npbs_rdel Deletes a PBS advance, standing, or job-specific reservation\\npbs_release_nodes Releases sister hosts or vnodes assigned to a PBS job\\npbs_rstat Shows status of PBS advance, standing, or job-specific reservations\\npbs_rsub Creates a PBS advance, standing, or job-specific reservation\\npbs_tclsh Depr ecated .  TCL shell with TCL-wrapped PBS API\\npbs_tmrsh TM-enabled replacement for rsh/ssh  for use by MPI implementations\\npbs_wish Depr ecated .  TK window shell with TCL-wrapped PBS API\\nqalter Alters a PBS job\\nqdel Deletes PBS jobs\\nqhold Holds PBS batch jobs\", metadata={'page': 14, 'source': '..\\\\guides\\\\raw\\\\PBSUserGuide2021.1.2.pdf'}),\n",
       " Document(page_content=\"3\\nPBS Professional  2021.1.2  User’s  Guide UG-31Job Input & Output Files\\n3.1 Introduction to Job File I/O in PBS\\nPBS allows you to manage input files, output files, standard output, and standard error .  PBS has two mechanisms for \\nhandling job files; you use staging for input and output files, and you select whether stdout  and/or stderr  are copied \\nback using the Keep_Files  job attribute.\\n3.2 Input/Output File Staging\\nFile staging is a way to specify which input files should be copied onto the execution host before the job starts, and which \\noutput files should be copied off the execution host when it finishes.    \\n3.2.1 Staging and Execution Directory: User Home vs. \\nJob-specific \\nA job's staging and execution directory  is the directory to which input files are staged, and from which output files are \\nstaged.  It is also the current working directory for the job script, for tasks started via the pbs_tm()  API, and for the \\nepilogue.  This directory is either your home directory or a job-specific directory created by PBS just for this job.  \\nPBS can create temporary directories specific to each job to be used as job staging and execution directories.  If each job has its own directories, you avoid filename collisions.  PBS creates these either under your home directory or under some other location depeding on how the execution host is configured.  \\nIf you use job-specific staging and execution directories, you don't need to have a home directory on each execution host, as long as those hosts are configured properly. \\nThis table lists the differences between using your home directory for staging and execution and using a job-specific staging and execution directory created by PBS.  \\nTable 3-1: Differences Between User Home and Job-specific Directory for Staging \\nand Execution\\nQuestion Regarding Action, \\nRequirement, or SettingUser Home DirectoryJob-specific \\nDirectory\\nDoes PBS have to create a job-specific staging and \\nexecution directory?No Yes if not in home direc -\\ntory\\nUser's home directory must exist on execution \\nhost(s)?Yes No\\nStandard out and standard error automatically deleted when \\nqsub -k  option is used?No Yes\", metadata={'page': 42, 'source': '..\\\\guides\\\\raw\\\\PBSUserGuide2021.1.2.pdf'})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = retriever.invoke(\"What is a PBS job?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reranking using a cross encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_encoder = CrossEncoder(model_name='cross-encoder/ms-marco-MiniLM-L-6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of documents to use as context in the prompt\n",
    "num_docs = 3\n",
    "\n",
    "def reranker(retrieved_documents: List[Document]):\n",
    "    \n",
    "    pairs = [[query, doc.page_content] for doc in retrieved_documents]\n",
    "    scores = cross_encoder.predict(pairs)\n",
    "    \n",
    "    # # printing out to see change in order\n",
    "    # print(\"New Ordering:\")\n",
    "    # for o in np.argsort(scores)[::-1]:\n",
    "    #     print(o+1)\n",
    "    \n",
    "    # Selecting top n\n",
    "    top_n =  [retrieved_documents[i] for i, v in enumerate(np.argsort(scores)[::-1]) if v in range(num_docs)]\n",
    "    \n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing our prompt and LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = dedent(\n",
    "       \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to aid in answering the question. \n",
    "       Keep the answer clear and concise, and support with examples if possible. Return the answer in a markdown format. \n",
    "       Question: {question}\n",
    "       Context: {context}\n",
    "       Answer:\"\"\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    # (\"system\", template),\n",
    "    (\"human\", template)\n",
    "])\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-pro\", max_output_tokens=2048, temperature=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating our chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to format the retrieved documents in a format the LLM can take\n",
    "def format_docs(docs: List[Document]) -> str:\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | RunnableLambda(reranker) | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To submit multiprocessor jobs, you can use the following steps:\n",
       "\n",
       "1. Create a job script that specifies the number of processors and the MPI command to be executed.\n",
       "2. Use the `qsub` command to submit the job script to PBS.\n",
       "3. PBS will then schedule the job and allocate the necessary resources.\n",
       "\n",
       "For example, the following job script requests 2 processors and runs the `mpiexec` command:\n",
       "\n",
       "```\n",
       "#!/bin/sh\n",
       "#PBS -l select=2:ncpus=2:mpiprocs=2\n",
       "#PBS -l walltime=00:10:00\n",
       "mpiexec -n 2 my_program\n",
       "```\n",
       "\n",
       "To submit this job script, you would use the following command:\n",
       "\n",
       "```\n",
       "qsub job_script.sh\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"How do I submit multiprocessor jobs?\"\n",
    "\n",
    "response = rag_chain.invoke(query)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onboarding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
